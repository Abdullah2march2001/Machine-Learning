{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "# Accept simple array as well as numpy array\n",
    "# X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "X = [[-1, 2], \n",
    "     [2, 6], \n",
    "     [2, 10], \n",
    "     [1, 18]]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.0220481   1.64461857]\n",
      "[0.96620647 0.03379353]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.14952879,  1.37267553],\n",
       "       [-2.89973262, -1.26156678],\n",
       "       [ 1.08457323, -0.90757969],\n",
       "       [ 8.96468817,  0.79647093]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pca.explained_variance_)       # The amount of variance explained by each of the selected components.\n",
    "print(pca.explained_variance_ratio_) # Percentage of variance explained by each of the selected components.\n",
    "\n",
    "#pca_X = pca.fit_transform(X) # Equal to fit and then transform..\n",
    "pca_X = pca.transform(X)\n",
    "pca_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  2.],\n",
       "       [ 2.,  6.],\n",
       "       [ 2., 10.],\n",
       "       [ 1., 18.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pca.inverse_transform(pca_X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svd_solver{‘auto’, ‘full’, ‘arpack’, ‘randomized’}, default=’auto’\n",
    "\n",
    "    If auto :\n",
    "    The solver is selected by a default policy based on X.shape and n_components: if the input data is larger \n",
    "    than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the \n",
    "    data, then the more efficient ‘randomized’ method is enabled. Otherwise the exact full SVD is computed and \n",
    "    optionally truncated afterwards.\n",
    "    \n",
    "    If full :\n",
    "    run exact full SVD calling the standard LAPACK solver via scipy.linalg.svd and select the components by \n",
    "    postprocessing\n",
    "    \n",
    "    If arpack :\n",
    "    run SVD truncated to n_components calling ARPACK solver via scipy.sparse.linalg.svds. It requires strictly 0 \n",
    "    < n_components < min(X.shape)\n",
    "    \n",
    "    If randomized :\n",
    "        run randomized SVD by the method of Halko et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.0220481   1.64461857]\n",
      "[0.96620647 0.03379353]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.14952879,  1.37267553],\n",
       "       [-2.89973262, -1.26156678],\n",
       "       [ 1.08457323, -0.90757969],\n",
       "       [ 8.96468817,  0.79647093]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "#If svd_solver='full' then default value for n_components = min(n_samples, n_features)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "pca_X = pca.transform(X)\n",
    "pca_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.0220481]\n",
      "[0.96620647]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.14952879],\n",
       "       [-2.89973262],\n",
       "       [ 1.08457323],\n",
       "       [ 8.96468817]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=1, svd_solver='arpack')\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "pca_X = pca.transform(X)\n",
    "pca_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Male', 1], ['Female', 3], ['Female', 2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case we have Gender values i.e. 'Male' and 'Female' Then \n",
    "# One hot Encoding for Female = 1 0 and Male = 0 1\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')# If handle_unknown='ignore' then sample which is missing \n",
    "                                            # during training, needed to tranform, results all bits zeros.\n",
    "X = [['Male', 1], \n",
    "     ['Female', 3], \n",
    "     ['Female', 2]]\n",
    "enc.fit(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows Categories 1=> ['Male', 'Female'] and  2=> [1, 2, 3]\n",
    "enc.categories_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are transforming the following two records to one hot encoding\n",
    "# As One Hot Encoding For Female => 1 0, and For Male => 0 1\n",
    "# As One Hot Encoding For 1 => 1 0 0, For 2 => 0 1 0 and For 3 => 0 0 1\n",
    "\n",
    "enc.transform([['Female', 2], ['Male', 4]]).toarray()\n",
    "\n",
    "# Thus ['Female', 1] = 1 0 1 0 0 As Female = 1 0, and 1 = 1 0 0\n",
    "# While ['Male', 4]  = 0 1 0 0 0 As Male   = 0 1, and 4 = 0 0 0 (As 4 is missing while creating one hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Male', 1],\n",
       "       [None, 2],\n",
       "       ['Female', None]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detault Featuers with a default prefixes are as;\n",
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding custom prefixes to the features, gender prefix is added for Male and Female and group for numbers\n",
    "enc.get_feature_names(['gender', 'group'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can always drop the first column for each Feature/ Category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To drop first column use drop=\"first\", In this case all bits will be considered zeros for first value.\n",
    "# When the drop parameter is specified, handle_unknown='ignore' throws error, as in this case conflict \n",
    "# occurs b/w \"Missing values\" and \"First value\" as all bits will be considered zeros for both.\n",
    "\n",
    "#drop_en = OneHotEncoder(drop='first', handle_unknown='ignore') # Not Allowed\n",
    "drop_en = OneHotEncoder(drop='first')\n",
    "\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "drop_en.fit(X)\n",
    "drop_en.categories_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop_en.transform([['Female', 4]]).toarray() # Not Allowed, as 4 is unknown category in this case\n",
    "\n",
    "# Here ['Male', 4] will create error, as 4 is not in the dataset, further, the drop parameter is used, \n",
    "# which does not allow unknown attributes, as all zeros bits are already assigned to first option\n",
    "\n",
    "\n",
    "# One Hot encode value for Female = 0 and Male = 1\n",
    "# One Hot encode value for decimal 1 = 0 0, For 2 = 1 0, and For 3 = 0 1\n",
    "drop_en.transform([['Female', 1], ['Male', 2], ['Male', 3]]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['x0_Male', 'x1_2', 'x1_3'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_en.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Female', 3],\n",
       "       ['Female', 2],\n",
       "       ['Female', 1]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_en.inverse_transform([[0, 0, 1], [0, 1, 0], [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop a column for feature only having 2 categories (Binary)\n",
    "\n",
    "* This works only with latest version of scikit-learn (0.23 and above)\n",
    "* To install latest version, run command below\n",
    "* pip intall scikit-learn == 0.23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_binary_enc = OneHotEncoder(drop='if_binary')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "\n",
    "drop_binary_enc.fit(X)\n",
    "drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "    1. Min-Max Normalization                   [0 , 1]\n",
    "    2. Mean Normalization                      [-0.5 , 0.5] # Implemenation Missing here in sklearn\n",
    "    3. Z-score Normalization (Standarization)  [-3 , 3]\n",
    "    4. Max-Absolute Normalization              [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 3], [3, 6], [0, 10], [1, 18]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [[-1, 3], \n",
    "        [3, 6], \n",
    "        [0, 10], \n",
    "        [1, 18]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in both dimensions:  [ 3. 18.]\n",
      "Minimum value in both dimensions:  [-1.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value in both dimensions: \", scaler.data_max_)\n",
    "print(\"Minimum value in both dimensions: \", scaler.data_min_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [1.         0.2       ]\n",
      " [0.25       0.46666667]\n",
      " [0.5        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75 1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform([[2, 18]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75       -0.06666667]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform([[2, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mean Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   3. Z-score Normalization [-3 , 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1, 2], \n",
    "        [2, 6], \n",
    "        [0, 10], \n",
    "        [1, 18]]\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "print(scaler.fit(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 9. ]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.34164079 -1.18321596]\n",
      " [ 1.34164079 -0.50709255]\n",
      " [-0.4472136   0.16903085]\n",
      " [ 0.4472136   1.52127766]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Max-Absolute Normalization [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5         0.11111111]\n",
      " [ 1.          0.33333333]\n",
      " [ 0.          0.55555556]\n",
      " [ 0.5         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "data = [[-1, 2], \n",
    "        [2, 6], \n",
    "        [0, 10], \n",
    "        [1, 18]]\n",
    "\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "maxabs = max_abs_scaler.fit_transform(data)\n",
    "print(maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5,  1. ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = [[ -1, 18]]\n",
    "X_test_maxabs = max_abs_scaler.transform(data_test)\n",
    "X_test_maxabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
